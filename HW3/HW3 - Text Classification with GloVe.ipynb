{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"080d50fc"},"outputs":[],"source":["import argparse\n","import logging\n","import time\n","\n","import torch\n","from torch.utils.data import DataLoader\n","from torch.utils.data.dataset import random_split\n","from torchtext.data.functional import to_map_style_dataset\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.datasets import DATASETS\n","from torchtext.prototype.transforms import load_sp_model, PRETRAINED_SP_MODEL, SentencePieceTokenizer\n","from torchtext.utils import download_from_url\n","from torchtext.vocab import build_vocab_from_iterator\n","import torch.nn as nn\n","from torch.nn.utils.rnn import pad_sequence\n","import torch.nn.functional as F\n","from torchtext.vocab import GloVe, FastText\n","from torchdata.datapipes.iter import IterableWrapper"]},{"cell_type":"markdown","metadata":{"id":"66eb271d"},"source":["### Information and Info\n","- torchtext repo: https://github.com/pytorch/text/tree/main/torchtext\n","- torchtext documentation: https://pytorch.org/text/stable/index.html\n","- Please FILL IN the parts that need to be filled in for this notebook."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6296,"status":"ok","timestamp":1676322589824,"user":{"displayName":"Longxiang Zhang","userId":"16336560205064417772"},"user_tz":300},"id":"8c949153","outputId":"db99be89-6049-4777-c3a2-05d0a93a4e60"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torchdata in /usr/local/lib/python3.8/dist-packages (0.5.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchdata) (2.25.1)\n","Requirement already satisfied: portalocker\u003e=2.0.0 in /usr/local/lib/python3.8/dist-packages (from torchdata) (2.7.0)\n","Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.8/dist-packages (from torchdata) (1.13.1+cu116)\n","Requirement already satisfied: urllib3\u003e=1.25 in /usr/local/lib/python3.8/dist-packages (from torchdata) (1.26.14)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1-\u003etorchdata) (4.4.0)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.8/dist-packages (from requests-\u003etorchdata) (2.10)\n","Requirement already satisfied: chardet\u003c5,\u003e=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests-\u003etorchdata) (4.0.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests-\u003etorchdata) (2022.12.7)\n"]}],"source":["!pip install torchdata\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":985,"status":"ok","timestamp":1676322590805,"user":{"displayName":"Longxiang Zhang","userId":"16336560205064417772"},"user_tz":300},"id":"sXMBwpmpWYXi","outputId":"b5495103-2519-42e7-9078-bf7d78eb9051"},"outputs":[{"name":"stdout","output_type":"stream","text":["ERROR: unknown command \"upgrade\"\n"]}],"source":["!pip upgrade torchdata"]},{"cell_type":"markdown","metadata":{"id":"12d93d22"},"source":["### Constants"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"329c056d"},"outputs":[],"source":["DATASET = \"AG_NEWS\"\n","DATA_DIR = \".data\"\n","DEVICE = \"cpu\"\n","EMBED_DIM = 300\n","LR = 4.0\n","BATCH_SIZE = 16\n","NUM_EPOCHS = 5\n","PADDING_VALUE = 0\n","PADDING_IDX = PADDING_VALUE\n","PAD = '\u003cpad\u003e'\n","UNK = '\u003cunk\u003e'\n","\n","# Fill this in with code to make this notebook run.\n","FILL_IN = \"FILL IN\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ffada8d0"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"1a61aede"},"source":["### Get the tokenizer\n","- Different models tolenize in different ways. \n","    - Word2Vec / GloVe does words (WordLevel).\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"93e3b7cb"},"outputs":[],"source":["\n","# Get the basic english tokenizer using the get_tokenizer function.\n","basic_english_tokenizer = get_tokenizer(\"basic_english\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aa4b78e4"},"outputs":[],"source":["# Do not remove this.\n","assert(len(basic_english_tokenizer(\"This is some text ...\")) == 7)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"505cf5ec"},"outputs":[],"source":["# Needed later.\n","TOKENIZER = basic_english_tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ca6d3edc"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"64096cd8"},"source":["### Get the data and get the vocabulary."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ce4a0578"},"outputs":[],"source":["# This function should loop over the (label, text) data pair and tokenize the text.\n","# It should yield a list of the tokens for each text.\n","def yield_tokens(data_iter):\n","    for _, text in data_iter:\n","        yield TOKENIZER(text)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f48f23ab"},"outputs":[],"source":["train_iter = DATASETS[DATASET](root=DATA_DIR, split=\"train\")\n","# Use build_vocab_from_iterator to build the vocabulary.\n","# This function should take yield_tokens.\n","# The special characters are PAD and UNK.\n","VOCAB = build_vocab_from_iterator(yield_tokens(train_iter), specials=[PAD, UNK])\n","\n","# Make the default index the same as that of the unk_token.\n","VOCAB.set_default_index(VOCAB.get_stoi()[UNK])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1676322605025,"user":{"displayName":"Longxiang Zhang","userId":"16336560205064417772"},"user_tz":300},"id":"jg7-q8GYb9Bv","outputId":"5679e366-3700-4975-d4c5-b0c3ec8bc3aa"},"outputs":[{"data":{"text/plain":["95812"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["len(VOCAB)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":329},"executionInfo":{"elapsed":287154,"status":"error","timestamp":1676322892159,"user":{"displayName":"Longxiang Zhang","userId":"16336560205064417772"},"user_tz":300},"id":"qj4ardEnKI0S","outputId":"352e380a-9268-458f-8e9a-dab578b83633"},"outputs":[{"ename":"MessageError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-11-d5df0069828e\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    121\u001b[0m       'TBE_EPHEM_CREDS_ADDR'] if ephemeral else _os.environ['TBE_CREDS_ADDR']\n\u001b[1;32m    122\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 123\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    124\u001b[0m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   request_id = send_request(\n\u001b[1;32m    170\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--\u003e 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    100\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    101\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 102\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"840252c4"},"source":["### Get GloVe vectors"]},{"cell_type":"markdown","metadata":{"id":"930e9a0c"},"source":["Information about pretrained vectors: \n","- https://pytorch.org/text/stable/_modules/torchtext/vocab/vectors.html#GloVe\n","- https://github.com/pytorch/text/blob/e3799a6eecef451f6e66c9c20b6432c5f078697f/torchtext/vocab/vectors.py#L263"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c4589bd6"},"outputs":[],"source":["# Set GLOVE to the name='840B' GloVe vectors of dimension 300. \n","GLOVE = GloVe(name='840B', dim=300)"]},{"cell_type":"markdown","metadata":{"id":"10318bc7"},"source":["If the embeddings are not in the token space, a zero vector will be returned."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"29ddde2a"},"outputs":[],"source":["# Get the vectors for all the tokens in s = \"Hello, How are you?\"\n","# Look up \"get_vecs_by_tokens\" for GloVe vectors.\n","# Add an assertion checking that the dimensions of wat you get is dimension (???, 300).\n","assert(GLOVE.get_vecs_by_tokens(TOKENIZER(\"Hello, How are you?\")).shape[-1] == 300)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":243,"status":"ok","timestamp":1676322923030,"user":{"displayName":"Longxiang Zhang","userId":"16336560205064417772"},"user_tz":300},"id":"df54d06b","outputId":"2fb8dd7b-e3c4-4621-fa45-9e5291a6347a"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.2720, -0.0620, -0.1884,  ...,  0.1302, -0.1832,  0.1323],\n","        [-0.1731,  0.2066,  0.0165,  ...,  0.1666, -0.3834, -0.0738],\n","        [-0.1731,  0.2066,  0.0165,  ...,  0.1666, -0.3834, -0.0738],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n"]}],"source":["# Let s = \"\"\u003cpad\u003e \u003cunk\u003e the man Man ahsdhashdahsdhash\".\n","# What are the vectors of each token. Print this below.\n","print(GLOVE.get_vecs_by_tokens(TOKENIZER(\"\u003cpad\u003e \u003cunk\u003e the man Man ahsdhashdahsdhash\")))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"90d5cc95"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"200b05fc"},"source":["### Helper functions"]},{"cell_type":"markdown","metadata":{"id":"6391c2a8"},"source":["These functions tokenize the string input and then map each token to the integer representation in the vocabulary."]},{"cell_type":"code","execution_count":53,"metadata":{"executionInfo":{"elapsed":144,"status":"ok","timestamp":1676329152658,"user":{"displayName":"Longxiang Zhang","userId":"16336560205064417772"},"user_tz":300},"id":"16ca1ef5"},"outputs":[],"source":["# Return for a sentence the int tokens for that sentence.\n","# I.e., you pass in \"a b c d\" and get out [1, 2, 3, 4].\n","def text_pipeline(text):\n","    return GLOVE.get_vecs_by_tokens(text).to(torch.int64)\n","\n","# Return the label starting at 0. I.e. map each label to fo from 0, not 2 or whatever it starts from.\n","def label_pipeline(label):\n","    return label - 1"]},{"cell_type":"markdown","metadata":{"id":"67ef6734"},"source":["Nice link on collate_fn and DataLoader in PyTorch: https://python.plainenglish.io/understanding-collate-fn-in-pytorch-f9d1742647d3"]},{"cell_type":"code","execution_count":54,"metadata":{"executionInfo":{"elapsed":122,"status":"ok","timestamp":1676329154047,"user":{"displayName":"Longxiang Zhang","userId":"16336560205064417772"},"user_tz":300},"id":"ff479986"},"outputs":[],"source":["# As we loop through batches, this function gets applied to each raw batch.\n","def collate_batch(batch):\n","    label_list, text_list = [], []\n","    for (label, text) in batch:\n","        # Get the label from {1, 2, 3, 4} to {0, 1, 2, 3}\n","        # Append the label to the label_list.\n","        label_list.append(label_pipeline(label))\n","                \n","        # Return a list of ints.\n","        # Get a torch tensor of the sentence, this sould be a tensor of torch.int64.\n","        processed_text = text_pipeline(text).to(torch.int64)\n","        text_list.append(processed_text.clone().detach())\n","    \n","    # Transform the label_list into a tensor. \n","    label_list = torch.Tensor(label_list)\n","    # Pad the list of text_list tensors so they all have the same length.\n","    # Use batch_first = True.\n","    # Use padding_valid = PADDING_VALUE\n","    text_list = pad_sequence(text_list, batch_first=True, padding_value=PADDING_VALUE)\n","            \n","    return label_list.to(DEVICE), text_list.to(DEVICE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2e1287d3"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"c7fcf425"},"source":["### Get the data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1889,"status":"ok","timestamp":1676322924917,"user":{"displayName":"Longxiang Zhang","userId":"16336560205064417772"},"user_tz":300},"id":"e617ddce","outputId":"c1c8fee4-b608-491d-faaa-4cf8f4b90164"},"outputs":[{"name":"stdout","output_type":"stream","text":["The number of classes is 4 ...\n"]}],"source":["train_iter = DATASETS[DATASET](root=DATA_DIR, split=\"train\")\n","# Get the number of classes.\n","num_class = len(set([label for label, _ in train_iter]))\n","# What are the classes?\n","print(f\"The number of classes is {num_class} ...\")"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":110,"status":"ok","timestamp":1676329128964,"user":{"displayName":"Longxiang Zhang","userId":"16336560205064417772"},"user_tz":300},"id":"7770ac24","outputId":"58b161cd-cb3a-49d6-b641-adb90a36cbc4"},"outputs":[{"data":{"text/plain":["tensor([1])"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["a = torch.Tensor([1.2]).to(torch.int64)\n","a"]},{"cell_type":"markdown","metadata":{"id":"5aa8a40d"},"source":["### Set up the model"]},{"cell_type":"code","execution_count":56,"metadata":{"executionInfo":{"elapsed":135,"status":"ok","timestamp":1676329228083,"user":{"displayName":"Longxiang Zhang","userId":"16336560205064417772"},"user_tz":300},"id":"dc51c359"},"outputs":[],"source":["# A more complicated model. We'll explore this after we learn word embeddings.\n","class TextClassificationModel(nn.Module):\n","    def __init__(\n","        self,\n","        vocab_size,\n","        embed_dim,\n","        num_class,\n","        initialize_with_glove = True,\n","        fine_tune_embeddings = True\n","    ):\n","        super(TextClassificationModel, self).__init__()\n","        # Set to an embedding of (vocab_size, embed_dim) size.\n","        # Use padding_idx = PADDING_IDX.\n","        # This is so we don't get gradients for padding tokens and use 0 as the vector for these.\n","        self.embedding = nn.Embedding(\n","            vocab_size,\n","            embed_dim,\n","            padding_idx=PADDING_IDX\n","        )\n","        \n","        if initialize_with_glove:\n","            # Turn off the gradient for the embedding weight as we are going to modify it. \n","            with torch.no_grad():\n","              for i in range(vocab_size):\n","                  # Get the token index in VOCAB.\n","                  token = VOCAB.get_itos()[i]\n","                  \n","                  # Modify the embedding matrix to be the GloVe vector for this token.\n","                  self.embedding.weight[i, :] = GLOVE.get_vecs_by_tokens(token, lower_case_backup=False)\n","            # Turn on the gradient after we modify it.\n","            # You could do this in another way by wrapping this in @torch.no_grad decorator.\n","            # self.embedding.requires_grad = True\n","        \n","        # No fine tuning means once you intialize, these are constant.\n","        if not fine_tune_embeddings:\n","            # Turn off the gradient for the embedding weight matric if you don't fine tune them.\n","            self.embedding.requires_grad = False\n","        \n","        \n","        # Set fc to be a linear layer of dimension (embed_dim, num_class).\n","        self.fc = nn.Linear(embed_dim, num_class)\n","        self.init_weights()\n","\n","    def init_weights(self):\n","        initrange = 0.5\n","        self.embedding.weight.data.uniform_(-initrange, initrange)\n","        self.fc.weight.data.uniform_(-initrange, initrange)\n","        self.fc.bias.data.zero_()\n","\n","    def forward(self, text):\n","        # Get the embeddings for all tokens in the batch of text.\n","        embedded = self.embedding(text)\n","        # Across dimension 1, get the mean vector. This gets the mean vector per sentence in the batch.\n","        # Make sure you squeeze any dimension that's 1. This should be (N, d), where N is the batch dimension and d is the word vector dimension.\n","        embedded_sum = embedded.mean(axis=1)\n","        # Run through a linear layer self.fc and also apply ReLU.\n","        logits = F.ReLU(self.fc(embedded_sum))\n","        return logits"]},{"cell_type":"markdown","metadata":{"id":"3b3c6ed5"},"source":["### Set up the "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"cef585f4"},"outputs":[],"source":["# Set to be the CrossEntropyLoss.\n","criterion = nn.CrossEntropyLoss()\n","# Set model to the TextClassification model.\n","# Turn on intialize_with_glove ad fine_tune_embeddings.\n","model = TextClassificationModel(vocab_size=len(VOCAB),\n","                                embed_dim=300,\n","                                num_class=num_class)\n","\n","# Set the optimizer for SGD with learning rate LR. The parameters are model.parameters.\n","optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n","# Schedule the learning rate decay to go down each epoch by 1/10.\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1.0, gamma=0.1)"]},{"cell_type":"markdown","metadata":{"id":"26266d8a"},"source":["### Set up the data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9c0aebb5"},"outputs":[],"source":["train_iter, test_iter = DATASETS[DATASET]()\n","# This puts things in a nice format.\n","train_dataset = to_map_style_dataset(train_iter)\n","test_dataset = to_map_style_dataset(test_iter)\n","\n","# Set num_train to 95% length of train_dataset.\n","# This should be an integer.\n","num_train = int(len(train_dataset)*0.95)\n","# The array below should have 2 ints in it, num_train, and the 5% left over for validation.\n","split_train_, split_valid_ = random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n","\n","# Set to a DataLoader on the training data with batch_size BATCH_SIZE and specify collate_batch.\n","train_dataloader = DataLoader(dataset=split_train_, batch_size=BATCH_SIZE, collate_fn=collate_batch)\n","valid_dataloader = DataLoader(dataset=split_valid_, batch_size=BATCH_SIZE, collate_fn=collate_batch)\n","test_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_batch)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"85773616"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"86476e2a"},"source":["### Train the model"]},{"cell_type":"code","execution_count":49,"metadata":{"executionInfo":{"elapsed":149,"status":"ok","timestamp":1676328995789,"user":{"displayName":"Longxiang Zhang","userId":"16336560205064417772"},"user_tz":300},"id":"24950481"},"outputs":[],"source":["def train(dataloader, model, optimizer, criterion, epoch):\n","    model.train()\n","    total_acc, total_count = 0, 0\n","    log_interval = 500\n","\n","    for idx, (label, text) in enumerate(dataloader):\n","        # Zero the gradients.\n","        optimizer.zero_grad()\n","        \n","        logits = model(text)\n","                \n","        # Get the loss.\n","        loss = criterion(logits, label)\n","        \n","        # Do back propagation.\n","        loss.backward()\n","        \n","        # Clip the gradients at 0.1\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n","        \n","        # Do an optimization step.\n","        optimizer.step()\n","        \n","        # Get the accuracy for this batch.\n","        total_acc += torch.eq(label, torch.argmax(logits, dim=1))\n","        # Get the number of rows in this batch. Use labels.\n","        total_count += len(label)\n","        \n","        if idx % log_interval == 0 and idx \u003e 0:\n","            print(\n","                \"| epoch {:3d} | {:5d}/{:5d} batches \"\n","                \"| accuracy {:8.3f}\".format(epoch, idx, len(dataloader), total_acc / total_count)\n","            )\n","            total_acc, total_count = 0, 0"]},{"cell_type":"code","execution_count":50,"metadata":{"executionInfo":{"elapsed":362,"status":"ok","timestamp":1676328997679,"user":{"displayName":"Longxiang Zhang","userId":"16336560205064417772"},"user_tz":300},"id":"39a702be"},"outputs":[],"source":["def evaluate(dataloader, model):\n","    model.eval()\n","    total_acc, total_count = 0, 0\n","\n","    with torch.no_grad():\n","        for idx, (label, text) in enumerate(dataloader):\n","            logits = model(text)\n","            total_acc += FILL_IN\n","            total_count += FILL_IN\n","    return total_acc / total_count"]},{"cell_type":"code","execution_count":58,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":381},"executionInfo":{"elapsed":177,"status":"error","timestamp":1676330548915,"user":{"displayName":"Longxiang Zhang","userId":"16336560205064417772"},"user_tz":300},"id":"a9e02c09","outputId":"ac05643f-32cc-4092-f1b1-080d121d3a4c"},"outputs":[{"ename":"TypeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-58-25d55d1b7d59\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0maccu_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m\u003cipython-input-49-1c642c8b2ff7\u003e\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, optimizer, criterion, epoch)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Get the loss.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 13\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Do back propagation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-\u003e 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u003e\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1174\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1175\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                label_smoothing=self.label_smoothing)\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3024\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3025\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 3026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: cross_entropy_loss(): argument 'input' (position 1) must be Tensor, not ReLU"]}],"source":["for epoch in range(1, NUM_EPOCHS + 1):\n","    epoch_start_time = time.time()\n","    train(train_dataloader, model, optimizer, criterion, epoch)\n","    accu_val = evaluate(valid_dataloader, model)\n","    scheduler.step()\n","    print(\"-\" * 59)\n","    print(\n","        \"| end of epoch {:3d} | time: {:5.2f}s | \"\n","        \"valid accuracy {:8.3f} \".format(epoch, time.time() - epoch_start_time, accu_val)\n","    )\n","    print(\"-\" * 59)\n","\n","print(\"Checking the results of test dataset.\")\n","accu_test = evaluate(test_dataloader, model)\n","print(\"test accuracy {:8.3f}\".format(accu_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9f3b2754"},"outputs":[],"source":[]}],"metadata":{"colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.15"}},"nbformat":4,"nbformat_minor":5}